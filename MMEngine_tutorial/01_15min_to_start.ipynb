{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "**MMEngine intro**: https://mmengine.readthedocs.io/en/latest/get_started/introduction.html\n",
    "\n",
    "**MMEngine 15min to start**: https://mmengine.readthedocs.io/en/latest/get_started/15_minutes.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "\n",
    "## Build a model\n",
    "\n",
    "A model class needs to inherit from `BaseModel`.\n",
    "\n",
    "The `forward` method should receive inputs from the dataset.\n",
    "\n",
    "The parameter `mode` has following common options:\n",
    "* loss: return loss\n",
    "* predict: return prediction results and gt\n",
    "* tensor: return prediction results, this option is used in model complexity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from mmengine.model import BaseModel\n",
    "\n",
    "class MMResNet50(BaseModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = torchvision.models.resnet50()\n",
    "\n",
    "    def forward(self, imgs, labels=None, mode=\"tensor\"):\n",
    "        x = self.resnet(imgs)\n",
    "        if mode == \"loss\":\n",
    "            return {\"loss\": F.cross_entropy(x, labels)}\n",
    "        elif mode == \"predict\":\n",
    "            return x, labels\n",
    "        elif mode == \"tensor\":\n",
    "            return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a dataset and dataloader\n",
    "\n",
    "The Torchvision built-in datasets are good enough in this simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "norm_cfg = dict(mean=[0.491, 0.482, 0.447], std=[0.202, 0.199, 0.201])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    dataset=torchvision.datasets.CIFAR10(\n",
    "        './data/cifar10',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(**norm_cfg)\n",
    "        ])\n",
    "    )\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    dataset=torchvision.datasets.CIFAR10(\n",
    "        './data/cifar10',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(**norm_cfg)\n",
    "        ])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a evaluation metric\n",
    "\n",
    "The evaluation metric class needs to inherit from `BaseMetric` and should have `process` and `compute_metrics` methods.\n",
    "\n",
    "`process` method accepts `data_batch` (a batch of inputs) and `data_samples` (a batch of outputs) as parameters. The processed information is saved to `self.results` property.\n",
    "\n",
    "`compute_metrics` accepts a `result` parameter, which is all the information save in `process`. These computed evaluation metric is returned in a `dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.evaluator import BaseMetric\n",
    "\n",
    "class Accuracy(BaseMetric):\n",
    "    def process(self, data_batch, data_samples):\n",
    "        score, gt = data_samples\n",
    "        self.results.append({\n",
    "            \"batch_size\": len(gt),\n",
    "            \"correct\": (score.argmax(dim=1) == gt).sum().cpu()\n",
    "        })\n",
    "\n",
    "    def compute_metrics(self, results):\n",
    "        total_correct = sum(item[\"correct\"] for item in results)\n",
    "        total_size = sum(item[\"batch_size\"] for item in results)\n",
    "        return dict(accuracy=100 * total_correct / total_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a runner and run the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from mmengine.runner import Runner\n",
    "\n",
    "runner = Runner(\n",
    "    # the model used for training and validation.\n",
    "    # Needs to meet specific interface requirements\n",
    "    model=MMResNet50(),\n",
    "    # working directory which saves training logs and weight files\n",
    "    work_dir='./logs_and_checkpoints',\n",
    "    # train dataloader needs to meet the PyTorch data loader protocol\n",
    "    train_dataloader=train_dataloader,\n",
    "    # optimize wrapper for optimization with additional features like\n",
    "    # AMP, gradtient accumulation, etc\n",
    "    optim_wrapper=dict(optimizer=dict(type=SGD, lr=0.001, momentum=0.9)),\n",
    "    # trainging coinfs for specifying training epoches, verification intervals, etc\n",
    "    # by_epoch means whether you're in EpochBased mode or IterBased mode\n",
    "        # by_epoch option affect the frequency of logging, checkpoint saving, and validation\n",
    "        # Ref1: https://mmengine.readthedocs.io/en/latest/common_usage/set_interval.html\n",
    "        # Ref2: https://mmengine.readthedocs.io/en/latest/common_usage/epoch_to_iter.html\n",
    "    train_cfg=dict(by_epoch=True, max_epochs=5, val_interval=1),\n",
    "    # validation dataloaer also needs to meet the PyTorch data loader protocol\n",
    "    val_dataloader=val_dataloader,\n",
    "    # validation configs for specifying additional parameters required for validation\n",
    "    val_cfg=dict(),\n",
    "    # validation evaluator. The default one is used here\n",
    "    val_evaluator=dict(type=Accuracy),\n",
    "    # whether you want to resume training or start a fresh training\n",
    "    resume=True,\n",
    "    # Specify the checkpoint path\n",
    "    # load_from='./work_dir/epoch_2.pth',\n",
    ")\n",
    "\n",
    "runner.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the FLOPs and parameters of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+------------------------+----------------------+------------+--------------+\n",
      "|\u001b[1m \u001b[0m\u001b[1mmodule                \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#parameters or shape\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#flops    \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#activations\u001b[0m\u001b[1m \u001b[0m|\n",
      "+------------------------+----------------------+------------+--------------+\n",
      "| resnet                 | 25.557M              | 4.145G     | 11.115M      |\n",
      "|  conv1                 |  9.408K              |  0.118G    |  0.803M      |\n",
      "|   conv1.weight         |   (64, 3, 7, 7)      |            |              |\n",
      "|  bn1                   |  0.128K              |  4.014M    |  0           |\n",
      "|   bn1.weight           |   (64,)              |            |              |\n",
      "|   bn1.bias             |   (64,)              |            |              |\n",
      "|  layer1                |  0.216M              |  0.69G     |  4.415M      |\n",
      "|   layer1.0             |   75.008K            |   0.241G   |   2.007M     |\n",
      "|    layer1.0.conv1      |    4.096K            |    12.845M |    0.201M    |\n",
      "|    layer1.0.bn1        |    0.128K            |    1.004M  |    0         |\n",
      "|    layer1.0.conv2      |    36.864K           |    0.116G  |    0.201M    |\n",
      "|    layer1.0.bn2        |    0.128K            |    1.004M  |    0         |\n",
      "|    layer1.0.conv3      |    16.384K           |    51.38M  |    0.803M    |\n",
      "|    layer1.0.bn3        |    0.512K            |    4.014M  |    0         |\n",
      "|    layer1.0.downsample |    16.896K           |    55.394M |    0.803M    |\n",
      "|   layer1.1             |   70.4K              |   0.224G   |   1.204M     |\n",
      "|    layer1.1.conv1      |    16.384K           |    51.38M  |    0.201M    |\n",
      "|    layer1.1.bn1        |    0.128K            |    1.004M  |    0         |\n",
      "|    layer1.1.conv2      |    36.864K           |    0.116G  |    0.201M    |\n",
      "|    layer1.1.bn2        |    0.128K            |    1.004M  |    0         |\n",
      "|    layer1.1.conv3      |    16.384K           |    51.38M  |    0.803M    |\n",
      "|    layer1.1.bn3        |    0.512K            |    4.014M  |    0         |\n",
      "|   layer1.2             |   70.4K              |   0.224G   |   1.204M     |\n",
      "|    layer1.2.conv1      |    16.384K           |    51.38M  |    0.201M    |\n",
      "|    layer1.2.bn1        |    0.128K            |    1.004M  |    0         |\n",
      "|    layer1.2.conv2      |    36.864K           |    0.116G  |    0.201M    |\n",
      "|    layer1.2.bn2        |    0.128K            |    1.004M  |    0         |\n",
      "|    layer1.2.conv3      |    16.384K           |    51.38M  |    0.803M    |\n",
      "|    layer1.2.bn3        |    0.512K            |    4.014M  |    0         |\n",
      "|  layer2                |  1.22M               |  1.043G    |  3.111M      |\n",
      "|   layer2.0             |   0.379M             |   0.379G   |   1.305M     |\n",
      "|    layer2.0.conv1      |    32.768K           |    0.103G  |    0.401M    |\n",
      "|    layer2.0.bn1        |    0.256K            |    2.007M  |    0         |\n",
      "|    layer2.0.conv2      |    0.147M            |    0.116G  |    0.1M      |\n",
      "|    layer2.0.bn2        |    0.256K            |    0.502M  |    0         |\n",
      "|    layer2.0.conv3      |    65.536K           |    51.38M  |    0.401M    |\n",
      "|    layer2.0.bn3        |    1.024K            |    2.007M  |    0         |\n",
      "|    layer2.0.downsample |    0.132M            |    0.105G  |    0.401M    |\n",
      "|   layer2.1             |   0.28M              |   0.221G   |   0.602M     |\n",
      "|    layer2.1.conv1      |    65.536K           |    51.38M  |    0.1M      |\n",
      "|    layer2.1.bn1        |    0.256K            |    0.502M  |    0         |\n",
      "|    layer2.1.conv2      |    0.147M            |    0.116G  |    0.1M      |\n",
      "|    layer2.1.bn2        |    0.256K            |    0.502M  |    0         |\n",
      "|    layer2.1.conv3      |    65.536K           |    51.38M  |    0.401M    |\n",
      "|    layer2.1.bn3        |    1.024K            |    2.007M  |    0         |\n",
      "|   layer2.2             |   0.28M              |   0.221G   |   0.602M     |\n",
      "|    layer2.2.conv1      |    65.536K           |    51.38M  |    0.1M      |\n",
      "|    layer2.2.bn1        |    0.256K            |    0.502M  |    0         |\n",
      "|    layer2.2.conv2      |    0.147M            |    0.116G  |    0.1M      |\n",
      "|    layer2.2.bn2        |    0.256K            |    0.502M  |    0         |\n",
      "|    layer2.2.conv3      |    65.536K           |    51.38M  |    0.401M    |\n",
      "|    layer2.2.bn3        |    1.024K            |    2.007M  |    0         |\n",
      "|   layer2.3             |   0.28M              |   0.221G   |   0.602M     |\n",
      "|    layer2.3.conv1      |    65.536K           |    51.38M  |    0.1M      |\n",
      "|    layer2.3.bn1        |    0.256K            |    0.502M  |    0         |\n",
      "|    layer2.3.conv2      |    0.147M            |    0.116G  |    0.1M      |\n",
      "|    layer2.3.bn2        |    0.256K            |    0.502M  |    0         |\n",
      "|    layer2.3.conv3      |    65.536K           |    51.38M  |    0.401M    |\n",
      "|    layer2.3.bn3        |    1.024K            |    2.007M  |    0         |\n",
      "|  layer3                |  7.098M              |  1.475G    |  2.158M      |\n",
      "|   layer3.0             |   1.512M             |   0.376G   |   0.652M     |\n",
      "|    layer3.0.conv1      |    0.131M            |    0.103G  |    0.201M    |\n",
      "|    layer3.0.bn1        |    0.512K            |    1.004M  |    0         |\n",
      "|    layer3.0.conv2      |    0.59M             |    0.116G  |    50.176K   |\n",
      "|    layer3.0.bn2        |    0.512K            |    0.251M  |    0         |\n",
      "|    layer3.0.conv3      |    0.262M            |    51.38M  |    0.201M    |\n",
      "|    layer3.0.bn3        |    2.048K            |    1.004M  |    0         |\n",
      "|    layer3.0.downsample |    0.526M            |    0.104G  |    0.201M    |\n",
      "|   layer3.1             |   1.117M             |   0.22G    |   0.301M     |\n",
      "|    layer3.1.conv1      |    0.262M            |    51.38M  |    50.176K   |\n",
      "|    layer3.1.bn1        |    0.512K            |    0.251M  |    0         |\n",
      "|    layer3.1.conv2      |    0.59M             |    0.116G  |    50.176K   |\n",
      "|    layer3.1.bn2        |    0.512K            |    0.251M  |    0         |\n",
      "|    layer3.1.conv3      |    0.262M            |    51.38M  |    0.201M    |\n",
      "|    layer3.1.bn3        |    2.048K            |    1.004M  |    0         |\n",
      "|   layer3.2             |   1.117M             |   0.22G    |   0.301M     |\n",
      "|    layer3.2.conv1      |    0.262M            |    51.38M  |    50.176K   |\n",
      "|    layer3.2.bn1        |    0.512K            |    0.251M  |    0         |\n",
      "|    layer3.2.conv2      |    0.59M             |    0.116G  |    50.176K   |\n",
      "|    layer3.2.bn2        |    0.512K            |    0.251M  |    0         |\n",
      "|    layer3.2.conv3      |    0.262M            |    51.38M  |    0.201M    |\n",
      "|    layer3.2.bn3        |    2.048K            |    1.004M  |    0         |\n",
      "|   layer3.3             |   1.117M             |   0.22G    |   0.301M     |\n",
      "|    layer3.3.conv1      |    0.262M            |    51.38M  |    50.176K   |\n",
      "|    layer3.3.bn1        |    0.512K            |    0.251M  |    0         |\n",
      "|    layer3.3.conv2      |    0.59M             |    0.116G  |    50.176K   |\n",
      "|    layer3.3.bn2        |    0.512K            |    0.251M  |    0         |\n",
      "|    layer3.3.conv3      |    0.262M            |    51.38M  |    0.201M    |\n",
      "|    layer3.3.bn3        |    2.048K            |    1.004M  |    0         |\n",
      "|   layer3.4             |   1.117M             |   0.22G    |   0.301M     |\n",
      "|    layer3.4.conv1      |    0.262M            |    51.38M  |    50.176K   |\n",
      "|    layer3.4.bn1        |    0.512K            |    0.251M  |    0         |\n",
      "|    layer3.4.conv2      |    0.59M             |    0.116G  |    50.176K   |\n",
      "|    layer3.4.bn2        |    0.512K            |    0.251M  |    0         |\n",
      "|    layer3.4.conv3      |    0.262M            |    51.38M  |    0.201M    |\n",
      "|    layer3.4.bn3        |    2.048K            |    1.004M  |    0         |\n",
      "|   layer3.5             |   1.117M             |   0.22G    |   0.301M     |\n",
      "|    layer3.5.conv1      |    0.262M            |    51.38M  |    50.176K   |\n",
      "|    layer3.5.bn1        |    0.512K            |    0.251M  |    0         |\n",
      "|    layer3.5.conv2      |    0.59M             |    0.116G  |    50.176K   |\n",
      "|    layer3.5.bn2        |    0.512K            |    0.251M  |    0         |\n",
      "|    layer3.5.conv3      |    0.262M            |    51.38M  |    0.201M    |\n",
      "|    layer3.5.bn3        |    2.048K            |    1.004M  |    0         |\n",
      "|  layer4                |  14.965M             |  0.812G    |  0.627M      |\n",
      "|   layer4.0             |   6.04M              |   0.374G   |   0.326M     |\n",
      "|    layer4.0.conv1      |    0.524M            |    0.103G  |    0.1M      |\n",
      "|    layer4.0.bn1        |    1.024K            |    0.502M  |    0         |\n",
      "|    layer4.0.conv2      |    2.359M            |    0.116G  |    25.088K   |\n",
      "|    layer4.0.bn2        |    1.024K            |    0.125M  |    0         |\n",
      "|    layer4.0.conv3      |    1.049M            |    51.38M  |    0.1M      |\n",
      "|    layer4.0.bn3        |    4.096K            |    0.502M  |    0         |\n",
      "|    layer4.0.downsample |    2.101M            |    0.103G  |    0.1M      |\n",
      "|   layer4.1             |   4.463M             |   0.219G   |   0.151M     |\n",
      "|    layer4.1.conv1      |    1.049M            |    51.38M  |    25.088K   |\n",
      "|    layer4.1.bn1        |    1.024K            |    0.125M  |    0         |\n",
      "|    layer4.1.conv2      |    2.359M            |    0.116G  |    25.088K   |\n",
      "|    layer4.1.bn2        |    1.024K            |    0.125M  |    0         |\n",
      "|    layer4.1.conv3      |    1.049M            |    51.38M  |    0.1M      |\n",
      "|    layer4.1.bn3        |    4.096K            |    0.502M  |    0         |\n",
      "|   layer4.2             |   4.463M             |   0.219G   |   0.151M     |\n",
      "|    layer4.2.conv1      |    1.049M            |    51.38M  |    25.088K   |\n",
      "|    layer4.2.bn1        |    1.024K            |    0.125M  |    0         |\n",
      "|    layer4.2.conv2      |    2.359M            |    0.116G  |    25.088K   |\n",
      "|    layer4.2.bn2        |    1.024K            |    0.125M  |    0         |\n",
      "|    layer4.2.conv3      |    1.049M            |    51.38M  |    0.1M      |\n",
      "|    layer4.2.bn3        |    4.096K            |    0.502M  |    0         |\n",
      "|  fc                    |  2.049M              |  2.048M    |  1K          |\n",
      "|   fc.weight            |   (1000, 2048)       |            |              |\n",
      "|   fc.bias              |   (1000,)            |            |              |\n",
      "|  avgpool               |                      |  0.1M      |  0           |\n",
      "+------------------------+----------------------+------------+--------------+\n",
      "\n",
      "Model Flops: 4.145G\n",
      "Model Parameters: 25.557M\n"
     ]
    }
   ],
   "source": [
    "from mmengine.analysis import get_model_complexity_info\n",
    "\n",
    "input_shape = (3, 224, 224)\n",
    "model = MMResNet50()\n",
    "analysis_results = get_model_complexity_info(model, input_shape)\n",
    "print(analysis_results[\"out_table\"])\n",
    "print(\"Model Flops: {}\".format(analysis_results[\"flops_str\"]))\n",
    "print(\"Model Parameters: {}\".format(analysis_results[\"params_str\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
